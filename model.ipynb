{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1428/1428\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 56ms/step - accuracy: 0.9787 - loss: 0.0848 - val_accuracy: 0.9946 - val_loss: 0.0258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9947 - loss: 0.0219\n",
      "Test Loss: 0.02579214982688427, Test Accuracy: 0.9945713877677917\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Data.csv\")\n",
    "df = df[['aX', 'aY', 'aZ', \"Result\"]]\n",
    "\n",
    "# Filter earthquake and non-earthquake samples\n",
    "earthquake = df[df[\"Result\"] == 1].iloc[:28600].reset_index(drop=True)\n",
    "no_earthquake = df[df[\"Result\"] == 0].iloc[:28600].reset_index(drop=True)\n",
    "\n",
    "# Split features for earthquake and no earthquake\n",
    "earthquake_X = earthquake[['aX', 'aY', 'aZ']].values\n",
    "no_earthquake_X = no_earthquake[['aX', 'aY', 'aZ']].values\n",
    "\n",
    "# Concatenate both classes into the final dataset\n",
    "X = np.concatenate((earthquake_X, no_earthquake_X))\n",
    "y = np.concatenate((np.ones(len(earthquake_X)), np.zeros(len(no_earthquake_X))))\n",
    "\n",
    "# Normalize the data\n",
    "X = X.astype('float32')\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)  # Standardize\n",
    "\n",
    "# Reshape into windows of 100 timesteps, each with 3 features (aX, aY, aZ)\n",
    "def create_dataset(data, window_size=100):\n",
    "    X = []\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        X.append(data[i:i + window_size])  # Extract 100 timesteps\n",
    "    return np.array(X)\n",
    "\n",
    "# Create windows of 100 timesteps for both earthquake and non-earthquake data\n",
    "X = create_dataset(X)\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y[:len(X)], test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data to match the BiLSTM input shape (samples, timesteps, features)\n",
    "# Each sample has 100 timesteps and 3 features (aX, aY, aZ)\n",
    "X_train = X_train.reshape((X_train.shape[0], 100, 3))\n",
    "X_test = X_test.reshape((X_test.shape[0], 100, 3))\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "# Define BiLSTM model\n",
    "model = Sequential([\n",
    "    Bidirectional(LSTM(128, return_sequences=False, dropout=0.3), input_shape=(100, 3)),  # 100 timesteps, 3 features\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(2, activation='softmax')  # Binary classification (earthquake or not)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=1,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"model/bilstm_model.h5\")\n",
    "\n",
    "# Optionally evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
